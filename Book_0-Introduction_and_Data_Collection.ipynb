{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to the 2013-2014 NBA season, SportVu tracking cameras were installed in all 30 NBA arenas. These six cameras would use cutting edge technology to track the exact location of all players, ref and the ball 25 times a second. This tracking data could later be used by teams, the league and privately run companies to provide new insights and analysis about the game of basketball.\n",
    "\n",
    "Although most of this data is heavily guarded, a small portion is available publicly on [NBA.com](http://stats.nba.com/tracking/). It is our hope to use this data, combining it with the previously available play-by-play and shot chart data, to create a model that will give us the probability that a given shot will go in. With this model we will explore many insights that could prove valuable to fans and teams alike.\n",
    "\n",
    "In this notebook, we go throughout the process of using the NBA.com API to gather the data we need. We then combine it all, a process that is not easy as one dataset is indexed differently than the others. In terms of time to run, this notebook takes by far the most time, so run it at your peril!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import a bunch of modules that may be helpful\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "import requests\n",
    "!pip install nbastats\n",
    "import nbastats.nbastats as nbastats\n",
    "!pip install py-goldsberry\n",
    "import goldsberry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first type of data that we want to get is the SportVu tracking data for all shots. These shots are sorted by player and are located on the ['Shot Log' page of their player profile](http://stats.nba.com/player/#!/201939/tracking/shotslogs/). So in order to get all the shots in a given year, we first need to get a list of players who were active in that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get players in season a\n",
    "def players(a):\n",
    "    url = \"http://stats.nba.com/stats/commonallplayers?\"\n",
    "    api_param = {'IsOnlyCurrentSeason':\"0\",\n",
    "                          'LeagueID': '00',\n",
    "                          'Season': '2015-16'}\n",
    "    pull = requests.get(url, params=api_param)\n",
    "    _headers = pull.json()['resultSets'][0]['headers']\n",
    "    _values = pull.json()['resultSets'][0]['rowSet']\n",
    "    season=pd.DataFrame([dict(zip(_headers, value)) for value in _values])\n",
    "    season = season.query(\"FROM_YEAR <= @a and TO_YEAR >= @a\")\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players2014=players('2014')\n",
    "players2013=players('2013')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other data that we want that is not already included with each player or each shot is the height of the player who is shooting it, along with the height of the closest defender. We will therefor also scrape the height of all the players, when available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height_2013 = []\n",
    "for indx,row in players2013.iterrows():\n",
    "    height_2013.append(goldsberry.player.demographics(row['PERSON_ID']).player_info()[0]['HEIGHT'])\n",
    "players2013['HEIGHT'] = height_2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height_2014 = []\n",
    "for indx,row in players2014.iterrows():\n",
    "    height_2014.append(goldsberry.player.demographics(row['PERSON_ID']).player_info()[0]['HEIGHT'])\n",
    "players2014['HEIGHT'] = height_2014   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this list of players in the two years for which we want data, we can write a function that gets a shot log of player for a given year, given his ID and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function for getting the shot log of a player given his ID and the year\n",
    "def shot_log(year,player_id):\n",
    "    api_param = {'DateFrom' : '',\n",
    "                    'DateTo' : '',\n",
    "                    'GameSegment': '',\n",
    "                    'LastNGames': 0,\n",
    "                    'LeagueID': \"00\",\n",
    "                    'Location': '',\n",
    "                    'Month': 0,\n",
    "                    'OpponentTeamID': 0,\n",
    "                    'Outcome': '',\n",
    "                    'Period': 0,\n",
    "                    'PlayerID': player_id,\n",
    "                    'Season': year,\n",
    "                    'SeasonSegment': '',\n",
    "                    'SeasonType': \"Regular Season\",\n",
    "                    'TeamID': 0,\n",
    "                    'VsConference':'',\n",
    "                    'VsDivision': ''\n",
    "                               }\n",
    "    pull=requests.get(\"http://stats.nba.com/stats/playerdashptshotlog?\",params=api_param)\n",
    "    headers = pull.json()['resultSets'][0]['headers']\n",
    "    values = pull.json()['resultSets'][0]['rowSet']\n",
    "    shots=pd.DataFrame([dict(zip(headers, value)) for value in values])\n",
    "    return shots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run this function all all players for both years. Notice that in this loop we are also using a function in one of the modules we imported to get the shot chart data for each shot. This provides us with new information like the type of shot, general area (Right, Left, Middle) of each shot, and x,y coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get shot chart and shot log for all players in 2014\n",
    "#Don't run, already been saved\n",
    "all_shots= pd.DataFrame()\n",
    "all_chart = pd.DataFrame()\n",
    "for index, row in players2014.iterrows():\n",
    "    chart = nbastats.ShotChart(row[\"PERSON_ID\"],season=\"2014-15\")\n",
    "    all_chart=all_chart.append(chart.shotchart())\n",
    "    shots = shot_log(\"2014-15\",row[\"PERSON_ID\"])\n",
    "    shots['PLAYER_ID']=row[\"PERSON_ID\"]\n",
    "    all_shots = all_shots.append(shots)\n",
    "all_shots.to_csv(\"all_shots_2014.csv\")\n",
    "all_chart.to_csv(\"all_chart_2014.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get shot chart and shot log for all players in 2013\n",
    "#Don't run, already been saved\n",
    "all_shots= pd.DataFrame()\n",
    "all_chart = pd.DataFrame()\n",
    "for index, row in season2013.iterrows():\n",
    "    shots = shot_log(\"2013-14\",row[\"PERSON_ID\"])\n",
    "    shots['PLAYER_ID']=row[\"PERSON_ID\"]\n",
    "    all_shots = all_shots.append(shots)\n",
    "    chart = nbastats.ShotChart(row[\"PERSON_ID\"],season=\"2013-14\")\n",
    "    all_chart=all_chart.append(chart.shotchart())\n",
    "all_shots.to_csv(\"all_shots_2013.csv\")\n",
    "all_chart.to_csv(\"all_chart_2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to merge these two data sources. What is annoying is that there is no common key for the shots, and moreover the game time at which each shot occurs varies across the datasets, as one is recorded by a computer and the other by hand. Another very annoying trait that occured is sometimes one dataset would say a shot occured while the other had no reference of it. Therefor, the process I used is to group the shots by the player who was shooting, and then group by game and quarter. If the amounts of shots were the same I would then merged the datasets ordered by game clock, the idea being that if one shot was before another in one dataset it would be before the other in the other data set. If the the amounts of shots were not the same I would then go through the shots and find the shot that occured closest to it - if they were within five seconds of eachother I would merge them, if not I would not merge them and drop that observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Merging shot chart data with player tracking for 2014\n",
    "## DO NOT RUN... takes a while\n",
    "def merge_shot_data(all_shots,all_chart):\n",
    "    players=set(all_shots['PLAYER_ID'])\n",
    "    joined_shots=pd.DataFrame()\n",
    "    joined_shots_1=pd.DataFrame()\n",
    "    for player in players:\n",
    "        shots = all_shots.loc[all_shots.PLAYER_ID==player].reset_index(drop=True)\n",
    "        chart = all_chart.loc[all_chart.PLAYER_ID==player].reset_index(drop=True)\n",
    "        split_time = shots.GAME_CLOCK.str.split(':')\n",
    "        col_names=[u'CLOSEST_DEFENDER', u'CLOSEST_DEFENDER_PLAYER_ID', u'CLOSE_DEF_DIST', \n",
    "                   u'DRIBBLES', u'FGM', u'FINAL_MARGIN', u'GAME_CLOCK', u'GAME_ID', u'LOCATION', \n",
    "                   u'MATCHUP', u'PERIOD', u'PTS', u'PTS_TYPE', u'SHOT_CLOCK', u'SHOT_DIST', \n",
    "                   u'SHOT_NUMBER', u'SHOT_RESULT', u'TOUCH_TIME', u'W',u'GRID_TYPE',u'GAME_EVENT_ID',\n",
    "                   u'PLAYER_ID', u'PLAYER_NAME', u'TEAM_ID',u'MINUTES_REMAINING', u'SECONDS_REMAINING', \n",
    "                   u'EVENT_TYPE', u'ACTION_TYPE', u'SHOT_TYPE', u'SHOT_ZONE_BASIC', \n",
    "                   u'SHOT_ZONE_AREA', u'SHOT_ZONE_RANGE', u'SHOT_DISTANCE', u'LOC_X', u'LOC_Y', \n",
    "                   u'SHOT_ATTEMPTED_FLAG', u'SHOT_MADE_FLAG']\n",
    "        time = pd.DataFrame(shots.GAME_CLOCK.str.split(':').tolist(), columns=\"MIN SECONDS\".split())\n",
    "        shots['MIN'] = time['MIN']\n",
    "        shots['SECONDS'] = time['SECONDS']\n",
    "        shots['TIME']=60*shots.MIN.astype(int)+shots.SECONDS.astype(int)\n",
    "        chart['TIME']=60*chart.MINUTES_REMAINING+chart.SECONDS_REMAINING\n",
    "        games = set(chart[\"GAME_ID\"])\n",
    "        for game in games:\n",
    "            game_shots_chart=chart.loc[chart.GAME_ID==game].reset_index(drop=True)\n",
    "            game_shots_log = shots.loc[shots.GAME_ID==game].reset_index(drop=True)\n",
    "            if game_shots_chart.shape[0]==game_shots_log.shape[0]:\n",
    "                huh = pd.concat([game_shots_chart,game_shots_log],axis=1)\n",
    "                huh=huh[col_names]\n",
    "                joined_shots=joined_shots.append(huh)\n",
    "            else:\n",
    "                quarters=set(game_shots_chart['PERIOD'])\n",
    "                for quarter in quarters:\n",
    "                    same_period=game_shots_log.loc[(game_shots_log.PERIOD==quarter)].reset_index(drop=True)\n",
    "                    same_period_chart=game_shots_chart.loc[(game_shots_chart.PERIOD==quarter)].reset_index(drop=True)\n",
    "                    if (not same_period.empty) and (not same_period_chart.empty):\n",
    "                        if same_period_chart.shape[0]==same_period.shape[0]:\n",
    "                            huh = pd.concat([same_period_chart,same_period],axis=1)\n",
    "                            huh=huh[col_names]\n",
    "                            joined_shots=joined_shots.append(huh)\n",
    "                        else:\n",
    "                            for index,row in same_period_chart.iterrows():\n",
    "                                same_period['DIF']=abs(same_period.TIME-row.TIME)\n",
    "                                df=same_period.sort(['DIF'],ascending=True)\n",
    "                                same_time=same_period.loc[[0]]\n",
    "                                if same_time.DIF[0]<5:\n",
    "                                    a=same_period_chart.loc[[index]].reset_index(drop=True)\n",
    "                                    huh=pd.concat([a,same_time],axis=1)\n",
    "                                    huh=huh[col_names]\n",
    "                                    joined_shots_1=joined_shots_1.append(huh,ignore_index=True)\n",
    "        print player\n",
    "    return joined_shots\n",
    "all_shots = pd.read_csv(\"all_shots_2013.csv\")\n",
    "all_chart = pd.read_csv(\"all_chart_2013.csv\")\n",
    "joined_shots = merge_shot_data(all_shots,all_chart)\n",
    "joined_shots.to_csv(\"joined_shots_2013.csv\")\n",
    "all_shots = pd.read_csv(\"all_shots_2014.csv\")\n",
    "all_chart = pd.read_csv(\"all_chart_2014.csv\")\n",
    "joined_shots = merge_shot_data(all_shots,all_chart)\n",
    "joined_shots.to_csv(\"joined_shots_2014.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that took a while! Now what we want to do is get the height of the shooter and closest defender, when available. To maximize the speed of this we can get a subset that belongs to each player (first on offense, then defense) and then set that whole column equal to the height. Doing so for 2013..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all2013=pd.read_csv('joined_shots_2013.csv')\n",
    "all2013['off_height']=0\n",
    "all2013['def_height']=0\n",
    "players_shot=list(set(all2013['PLAYER_ID']))\n",
    "players_def=list(set(all2013['CLOSEST_DEFENDER_PLAYER_ID']))\n",
    "for player in players_shot:\n",
    "    at = all2013[all2013['PLAYER_ID']==player].index.tolist()\n",
    "    hi = players2013.loc[players2013.PERSON_ID==player]['HEIGHT']\n",
    "    all2013['off_height'][at]=hi.iloc[0]\n",
    "for player in players_def:\n",
    "    at = all2013[all2013['CLOSEST_DEFENDER_PLAYER_ID']==player].index.tolist()\n",
    "    hi = players2013.loc[players2013.PERSON_ID==player]['HEIGHT']\n",
    "    all2013['def_height'][at]=hi.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now doing so for 2014..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all2014=pd.read_csv('joined_shots_2014.csv')\n",
    "all2014['off_height']=0\n",
    "all2014['def_height']=0\n",
    "players_shot=list(set(all2014['PLAYER_ID']))\n",
    "players_def=list(set(all2014['CLOSEST_DEFENDER_PLAYER_ID']))\n",
    "for player in players_shot:\n",
    "    at = all2014[all2014['PLAYER_ID']==player].index.tolist()\n",
    "    hi = players2014.loc[players2014.PERSON_ID==player]['HEIGHT']\n",
    "    all2014['off_height'][at]=hi.iloc[0]\n",
    "for player in players_def:\n",
    "    at = all2014[all2014['CLOSEST_DEFENDER_PLAYER_ID']==player].index.tolist()\n",
    "    hi = players2014.loc[players2014.PERSON_ID==player]['HEIGHT']\n",
    "    if len(hi)>0:\n",
    "        all2014['def_height'][at]=hi.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need our last piece of data, play by play. This dataset will provide us with other key pieces of information we need for our insights that we don't already have, like score differential at time of shot, whether the action before was a turnover (to identify fast break opportunities) and the ids of the players who are on the court.\n",
    "\n",
    "For this we will borrow heavily from the work of Darryl Blackport, who made his iPython Notebook on how to get play by play along with the players who are on the court at each moment [available online](http://nbviewer.ipython.org/github/dblackrun/nba/blob/master/ipython_notebooks/pbp_with_players_on_court.ipynb). However, I did have to add in some code, as his code was only for one specific game and when using it in a loop over all games we noticed it broke down in some instances. I will highlight those occations when we get to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import math\n",
    "import csv\n",
    "# base url for play by play for game id\n",
    "GAME_BASE_URL = \"http://stats.nba.com/stats/playbyplayv2?EndPeriod=10&EndRange=55800&GameID=<game_id>&RangeType=2&Season=2014-15&SeasonType=Regular+Season&StartPeriod=1&StartRange=0\"\n",
    "# base url for moment data for event id\n",
    "MOMENT_BASE_URL = \"http://stats.nba.com/stats/locations_getmoments/?eventid=<event_id>&gameid=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRawPbpForGame(game_id):\n",
    "    # for a given game_id, return a pandas data frame with the raw play by play\n",
    "    url = GAME_BASE_URL.replace(\"<game_id>\", game_id)\n",
    "        \n",
    "    response = urllib2.urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "\n",
    "    game_info = []\n",
    "    plays = []\n",
    "    for line in data['resultSets']:\n",
    "        if 'name' in line.keys() and line['name'] == 'PlayByPlay':\n",
    "            for event in line['rowSet']:\n",
    "                row = dict(zip([header for header in line['headers']],event))\n",
    "                plays.append(row)\n",
    "\n",
    "    return pd.DataFrame(plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is what he used to get the IDs of the players on the court at a given moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlayersOnFloorForMoment(game_id, event_id):\n",
    "    # for a given game_id and event_id, return a dict with a list players on the floor for each team and team ids\n",
    "    url = MOMENT_BASE_URL.replace(\"<event_id>\", str(event_id))\n",
    "    url = url + game_id\n",
    "    response = urllib2.urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    players = {}\n",
    "    players['home_team_id'] = data[\"moments\"][0][5][1][0]\n",
    "    players['away_team_id'] = data[\"moments\"][0][5][6][0]\n",
    "    players['home_player_ids'] =[]\n",
    "    players['away_player_ids'] =[]\n",
    "    for i in range(1,6):\n",
    "        players['home_player_ids'].append(data[\"moments\"][0][5][i][1])\n",
    "    for i in range(6,11):\n",
    "        players['away_player_ids'].append(data[\"moments\"][0][5][i][1])\n",
    "    return players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to edit it to be the following:\n",
    "\n",
    "We had to do this because for some moments in some games, there is not data at all. For clarification, each moment is a play, so a few seconds, and contains each observation of the players' positions 25 times seconds, so we are checking that data for the players' IDs. Therefor, if that was the case, we had to catch that error. If there was data there was also the case that some of the data could be missing - i.e. for the first of the datapoints about where the players were only 9 players were listed instead of 10. If that was the case then we had to go onto the next data point and see if there was complete data for that. If there was a time period with no moments (this usually happened to entire games, and I'm assuming because the cameras were turned off) then we just filled the moments with NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPlayersOnFloorForMoment(game_id, event_id):\n",
    "    # for a given game_id and event_id, return a dict with a list players on the floor for each team and team ids\n",
    "    url = MOMENT_BASE_URL.replace(\"<event_id>\", str(event_id))\n",
    "    url = url + game_id\n",
    "    players = {}\n",
    "    try: \n",
    "        r = urllib2.urlopen(url)\n",
    "    except urllib2.URLError, e:\n",
    "        r = e\n",
    "    if(r.code==200):\n",
    "        response = urllib2.urlopen(url)\n",
    "        data = json.loads(response.read())\n",
    "        if data[\"moments\"]:\n",
    "            huh=0\n",
    "            found=0\n",
    "            addit=0\n",
    "            while found==0:\n",
    "                if len(data[\"moments\"][huh][5])==11:\n",
    "                    found =1\n",
    "                elif (len(data[\"moments\"][huh][5])==10):\n",
    "                    if (data[\"moments\"][huh][5][0][1]>10):\n",
    "                        found =1\n",
    "                        addit=-1\n",
    "                    elif huh ==(len(data[\"moments\"])-1):\n",
    "                        found = 2\n",
    "                    else:\n",
    "                        huh=huh+1\n",
    "                elif huh ==(len(data[\"moments\"])-1):\n",
    "                    found = 2\n",
    "                else:\n",
    "                    huh=huh+1\n",
    "            if found==1:\n",
    "                players['home_team_id'] = data[\"moments\"][huh][5][1][0]\n",
    "                players['away_team_id'] = data[\"moments\"][huh][5][6][0]\n",
    "                players['home_player_ids'] =[]\n",
    "                players['away_player_ids'] =[]\n",
    "                for i in range(1,6):\n",
    "                    players['home_player_ids'].append(data[\"moments\"][huh][5][i+addit][1])\n",
    "                for i in range(6,11):\n",
    "                    players['away_player_ids'].append(data[\"moments\"][huh][5][i+addit][1])\n",
    "            elif found ==2:\n",
    "                players['home_team_id'] = np.nan\n",
    "                players['away_team_id'] = np.nan\n",
    "                players['home_player_ids'] = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "                players['away_player_ids'] = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "        else:\n",
    "            players['home_team_id'] = np.nan\n",
    "            players['away_team_id'] = np.nan\n",
    "            players['home_player_ids'] = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            players['away_player_ids'] = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "    else:\n",
    "            players['home_team_id'] = np.nan\n",
    "            players['away_team_id'] = np.nan\n",
    "            players['home_player_ids'] = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "            players['away_player_ids'] = [np.nan,np.nan,np.nan,np.nan,np.nan]\n",
    "    return players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Blackport's code he got the list of players on the court for the entire period by getting it for the first action and then keeping track of substituions. His code was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlayersOnFloorForPeriod(period):\n",
    "    # for a given period data frame, return a data frame with new columns for the players on the floor\n",
    "    period = period.reset_index(drop=True)\n",
    "    start_event_num = period['EVENTNUM'].min()\n",
    "    period_number = period['PERIOD'].mean()\n",
    "    if period_number == 1 or period_number == 3 or period_number > 4:\n",
    "        start_event_num += 1\n",
    "    period_starters = getPlayersOnFloorForMoment(game_id, start_event_num)\n",
    "    period['HOME_TEAM_ID'] = period_starters[\"home_team_id\"]\n",
    "    period['AWAY_TEAM_ID'] = period_starters[\"away_team_id\"]\n",
    "    period['HOME_PLAYER1_ID'] = period_starters['home_player_ids'][0]\n",
    "    period['HOME_PLAYER2_ID'] = period_starters['home_player_ids'][1]\n",
    "    period['HOME_PLAYER3_ID'] = period_starters['home_player_ids'][2]\n",
    "    period['HOME_PLAYER4_ID'] = period_starters['home_player_ids'][3]\n",
    "    period['HOME_PLAYER5_ID'] = period_starters['home_player_ids'][4]\n",
    "    period['AWAY_PLAYER1_ID'] = period_starters['away_player_ids'][0]\n",
    "    period['AWAY_PLAYER2_ID'] = period_starters['away_player_ids'][1]\n",
    "    period['AWAY_PLAYER3_ID'] = period_starters['away_player_ids'][2]\n",
    "    period['AWAY_PLAYER4_ID'] = period_starters['away_player_ids'][3]\n",
    "    period['AWAY_PLAYER5_ID'] = period_starters['away_player_ids'][4]\n",
    "    \n",
    "    # get index for all substitutions and for each one sub in and out appropriate players\n",
    "    subs = period[period['EVENTMSGTYPE'] == 8].index.tolist()\n",
    "    end = len(period.index)\n",
    "    for i in range(len(subs)):\n",
    "        if str(period['HOME_PLAYER1_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'HOME_PLAYER1_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['HOME_PLAYER2_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'HOME_PLAYER2_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['HOME_PLAYER3_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'HOME_PLAYER3_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['HOME_PLAYER4_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'HOME_PLAYER4_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['HOME_PLAYER5_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'HOME_PLAYER5_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['AWAY_PLAYER1_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'AWAY_PLAYER1_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['AWAY_PLAYER2_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'AWAY_PLAYER2_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['AWAY_PLAYER3_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'AWAY_PLAYER3_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['AWAY_PLAYER4_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'AWAY_PLAYER4_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "        elif str(period['AWAY_PLAYER5_ID'].iloc[subs[i]]) == str(period['PLAYER1_ID'][subs[i]]):\n",
    "            period.ix[subs[i]:end, 'AWAY_PLAYER5_ID'] = str(period['PLAYER2_ID'][subs[i]])\n",
    "    return period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep it mostly the same, but for the instances where we could not get data for the first moment of the period we tried the next five. This is our code (note the while loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlayersOnFloorForPeriod(period):\n",
    "    # for a given period data frame, return a data frame with new columns for the players on the floor\n",
    "    period = period.reset_index(drop=True)\n",
    "    start_event_num = period['EVENTNUM'].min()\n",
    "    period_number = period['PERIOD'].mean()\n",
    "    if period_number == 1 or period_number == 3 or period_number > 4:\n",
    "        start_event_num += 1\n",
    "    period_starters = getPlayersOnFloorForMoment(game_id, start_event_num)\n",
    "    tries=0\n",
    "    while (math.isnan(period_starters['home_team_id']))&(tries<5):\n",
    "        start_event_num=start_event_num+1   \n",
    "        period_starters = getPlayersOnFloorForMoment(game_id, start_event_num)\n",
    "        tries=tries+1\n",
    "    period['HOME_TEAM_ID'] = period_starters[\"home_team_id\"]\n",
    "    period['AWAY_TEAM_ID'] = period_starters[\"away_team_id\"]\n",
    "    period['HOME_PLAYER1_ID'] = period_starters['home_player_ids'][0]\n",
    "    period['HOME_PLAYER2_ID'] = period_starters['home_player_ids'][1]\n",
    "    period['HOME_PLAYER3_ID'] = period_starters['home_player_ids'][2]\n",
    "    period['HOME_PLAYER4_ID'] = period_starters['home_player_ids'][3]\n",
    "    period['HOME_PLAYER5_ID'] = period_starters['home_player_ids'][4]\n",
    "    period['AWAY_PLAYER1_ID'] = period_starters['away_player_ids'][0]\n",
    "    period['AWAY_PLAYER2_ID'] = period_starters['away_player_ids'][1]\n",
    "    period['AWAY_PLAYER3_ID'] = period_starters['away_player_ids'][2]\n",
    "    period['AWAY_PLAYER4_ID'] = period_starters['away_player_ids'][3]\n",
    "    period['AWAY_PLAYER5_ID'] = period_starters['away_player_ids'][4]\n",
    "    \n",
    "    # get index for all substitutions and for each one sub in and out appropriate players\n",
    "    subs = period[period['EVENTMSGTYPE'] == 8].index.tolist()\n",
    "    end = len(period.index)\n",
    "    for i in range(len(subs)):\n",
    "        if period['HOME_PLAYER1_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['HOME_PLAYER1_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['HOME_PLAYER2_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['HOME_PLAYER2_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['HOME_PLAYER3_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['HOME_PLAYER3_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['HOME_PLAYER4_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['HOME_PLAYER4_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['HOME_PLAYER5_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['HOME_PLAYER5_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['AWAY_PLAYER1_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['AWAY_PLAYER1_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['AWAY_PLAYER2_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['AWAY_PLAYER2_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['AWAY_PLAYER3_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['AWAY_PLAYER3_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['AWAY_PLAYER4_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['AWAY_PLAYER4_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "        elif period['AWAY_PLAYER5_ID'][subs[i]] == period['PLAYER1_ID'][subs[i]]:\n",
    "            period['AWAY_PLAYER5_ID'][subs[i]:end] = period['PLAYER2_ID'][subs[i]]\n",
    "    return period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run this code for all games. Note that it wrote it this way becuase I would run it for like 200 games at a time because it took a while. This is doing it for 2013 and saving it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc=21400001+c\n",
    "if c>0:\n",
    "    pbp_with_lineups=pd.read_csv('pbp_with_lineups.csv')\n",
    "for i in range(cc,21400021,1):\n",
    "    print(i)\n",
    "    game_id= \"00\" + str(i)\n",
    "    pbp = getRawPbpForGame(game_id)\n",
    "    if i == 21400001:\n",
    "        pbp_with_lineups = pbp.groupby(\"PERIOD\").apply(getPlayersOnFloorForPeriod)\n",
    "    else:\n",
    "        pbp_with_lineups1 = pbp.groupby(\"PERIOD\").apply(getPlayersOnFloorForPeriod)\n",
    "        pbp_with_lineups = pbp_with_lineups.append(pbp_with_lineups1)\n",
    "        pbp_with_lineups.to_csv('pbp_with_lineups.csv',index=False,header=True)\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbp_with_lineups.to_csv('playbyplay/pbp_with_lineups_2013.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is doing it for 2014..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc=21400001+c\n",
    "if c>0:\n",
    "    pbp_with_lineups=pd.read_csv('pbp_with_lineups.csv')\n",
    "for i in range(cc,21300021,1):\n",
    "    print(i)\n",
    "    game_id= \"00\" + str(i)\n",
    "    pbp = getRawPbpForGame(game_id)\n",
    "    if i == 21300001:\n",
    "        pbp_with_lineups = pbp.groupby(\"PERIOD\").apply(getPlayersOnFloorForPeriod)\n",
    "    else:\n",
    "        pbp_with_lineups1 = pbp.groupby(\"PERIOD\").apply(getPlayersOnFloorForPeriod)\n",
    "        pbp_with_lineups = pbp_with_lineups.append(pbp_with_lineups1)\n",
    "        pbp_with_lineups.to_csv('pbp_with_lineups.csv',index=False,header=True)\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbp_with_lineups.to_csv('playbyplay/pbp_with_lineups_2014.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! Now we have all the play by play data! However, it does not in its current form have all the data we want. Not every moment has score differential, only when a player scores. We want to change that, so we get it so that each moment now contains score differential. We can do this by just shifting the column down a spot, and when it contains a NaN overwrite it with the score above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbp2014=pd.read_csv('playbyplay/pbp_with_lineups_2014.csv')\n",
    "sort=pbp2014.sort(['GAME_ID','EVENTNUM'])\n",
    "all2014['EVENTNUM']=all2014['GAME_EVENT_ID']\n",
    "clean = sort.drop_duplicates(['GAME_ID','EVENTNUM'])\n",
    "k=0\n",
    "while (sum([(str(x) == 'nan') for x in clean.SCOREMARGIN])>0)&(k<50):\n",
    "    k+=1\n",
    "    print k\n",
    "    clean['SCOREMARGIN']=[y if str(x) =='nan' else x for x,y in zip(list(clean.SCOREMARGIN),[0]+list(clean.SCOREMARGIN)[:-1])]\n",
    "clean['SCOREMARGIN']=[0 if x=='TIE' else x for x in clean.SCOREMARGIN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other piece of information we want is the action of the moment before, to identify fastbreaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean['ACTION_BEFORE']=[\"nan\"]+list(clean.EVENTMSGTYPE)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that remains is to merge it with the shot data we have. Luckily, this proves pretty easy as the shot chart data (and therefor our merged shot data) has a unique identifier (game ID and moment ID) that is shared by play by play. Therefor, we just merge on those two columns, only retaining moments that are a shot. We also want the score margin to reflect the score from the shooters point of view (currently it is from the home team's point of view) so we negate it where necessary. We then save our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try1=clean.merge(all2014,on=['GAME_ID','EVENTNUM'])\n",
    "try1['SCOREMARGIN']=[-1*int(y) if x =='A' else y for x,y in zip(try1.LOCATION,try1.SCOREMARGIN)]\n",
    "try1.to_csv('merged_shots/merged_shots_14.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the same for the 2013 data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pbp2013=pd.read_csv('playbyplay/pbp_with_lineups_2013.csv')\n",
    "sort=pbp2013.sort(['GAME_ID','EVENTNUM'])\n",
    "all2013['EVENTNUM']=all2013['GAME_EVENT_ID']\n",
    "clean = sort.drop_duplicates(['GAME_ID','EVENTNUM'])\n",
    "k=0\n",
    "while (sum([(str(x) == 'nan') for x in clean.SCOREMARGIN])>0)&(k<50):\n",
    "    k+=1\n",
    "    print k\n",
    "    clean['SCOREMARGIN']=[y if str(x) =='nan' else x for x,y in zip(list(clean.SCOREMARGIN),[0]+list(clean.SCOREMARGIN)[:-1])]\n",
    "clean['ACTION_BEFORE']=[\"nan\"]+list(clean.EVENTMSGTYPE)[:-1]\n",
    "clean['SCOREMARGIN']=[0 if x=='TIE' else x for x in clean.SCOREMARGIN]\n",
    "try1=clean.merge(all2013,on=['GAME_ID','EVENTNUM'])\n",
    "try1['SCOREMARGIN']=[-1*int(y) if x =='A' else y for x,y in zip(try1.LOCATION,try1.SCOREMARGIN)]\n",
    "try1.to_csv('merged_shots/merged_shots_13.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And BOOM! We're all done! Now that we have the data that we need and merged it all, we can go onto more fun things, like our analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
